# 一、项目简介

## 1背景

目前，情感倾向分析的方法主要分为两类：一种是基于情感词典的方法；一种是基于机器学习的方法，如基于大规模语料库的机器学习。前者需要用到标注好的情感词典，英文的词典有很多，中文主要有知网整理的情感词典Hownet和台湾大学整理发布的NTUSD两个情感词典，还有哈工大信息检索研究室开源的《同义词词林》可以用于情感词典的扩充。基于机器学习的方法则需要大量的人工标注的语料作为训练集，通过提取文本特征，构建分类器来实现情感的分类。

文本情感分析的分析粒度可以是词语、句子也可以是段落或篇章。段落篇章级情感分析主要是针对某个主题或事件进行倾向性判断，一般需要构建对应事件的情感词典，如电影评论的分析，需要构建电影行业自己的情感词典效果会比通用情感词典效果更好；也可以通过人工标注大量电影评论来构建分类器。句子级的情感分析大多事通过计算句子里包含的所有情感词的平均值来得到。

篇章级的情感分析，也可以通过聚合篇章中所有的句子的情感倾向来计算得出。因此，针对句子级的情感倾向分析，既能解决较短文本的情感分析，同时也可以是篇章级文本情感分析的基础。



## 2.过程流设计

* 使用情感词典方法的过程流 : 

  ![](https://www.writebug.com/myres/static/uploads/2021/10/28/461448743e68d89250eee98524f2547e.writebug)






* 使用机器学习方法的过程流: 

  ![](https://www.writebug.com/myres/static/uploads/2021/10/28/08096a78642d165af39344b2e0bbe115.writebug)




## 3算法设计



### 3.1机器学习算法设计

#### 3.1.1背景

机器学习的方法精确度更高，因为词典匹配会由于语义表达的丰富性而出现很大误差，而机器学习方法不会。而且它可使用的场景更多样。无论是主客观分类还是正负面情感分类，机器学习都可以完成任务。而无需像词典匹配那样要深入到词语、句子、语法这些层面。

而词典方法适用的语料范围更广，无论是手机、电脑这些商品，还是书评、影评这些语料，都可以适用。但机器学习则极度依赖语料，把手机语料训练出来的的分类器拿去给书评分类，那是注定要失败的。

使用机器学习进行情感分析，可以换一个相同意思的说法，就是用有监督的（需要人工标注类别）机器学习方法来对文本进行分类。

这点与词典匹配有着本质的区别。词典匹配是直接计算文本中的情感词，得出它们的情感倾向分值。而机器学习方法的思路是先选出一部分表达积极情感的文本和一部分表达消极情感的文本，用机器学习方法进行训练，获得一个情感分类器。再通过这个情感分类器对所有文本进行积极和消极的二分分类。最终的分类可以为文本给出0或1这样的类别，也可以给出一个概率值，比如”这个文本的积极概率是90%，消极概率是10%“。

Python 有良好的程序包可以进行情感分类，那就是Python 自然语言处理包，Natural Language Toolkit ，简称NLTK 。同时Python 也有良好的程序包可以进行对中文文本进行分析，如jiaba。

#### 3.1.2算法框架

![](https://www.writebug.com/myres/static/uploads/2021/10/28/c500a76f9aed4182878f78caf822ffd8.writebug)

#### 3.1.3数据集

先以带有正向标签和负向标签的各1500条真实的中文酒店评论语料作为训练集用以训练分类器，剩余带有正向标签和负向标签的各500条真实的中文酒店评论语料作为测试集测试不同分类算法、不同特征提取方法、不同维度的准确度。

最后选择准确度最高的方案，将上述带有正向标签和负向标签的各2000条真实的中文酒店评论语料作为训练集训练最终存储的分类器。

保存用户输入的语句和反馈，定期挑拣出新增的训练数据以优化分类器。

#### 3.1.4维度和权重

不同分类方法、不同征选取方法、不同维度得到的测试准确率如下表：

##### 以所有词为特征提取方法

| 分类算法               | 准确率   |
| ------------------ | ----- |
| BernoulliNB        | 0.704 |
| MultinomiaNB       | 0.864 |
| LogisticRegression | 0.836 |
| SVC                | 0.555 |
| LinearSVC          | 0.821 |
| NuSVC              | 0.843 |

##### 以所有双词搭配为特征提取方法

| 分类算法               | 准确率   |
| ------------------ | ----- |
| BernoulliNB        | 0.56  |
| MultinomiaNB       | 0.854 |
| LogisticRegression | 0.827 |
| SVC                | 0.513 |
| LinearSVC          | 0.814 |
| NuSVC              | 0.781 |

##### 以所有词和所有双词搭配为特征提取取方法

| 分类算法               | 准确率   |
| ------------------ | ----- |
| BernoulliNB        | 0.64  |
| MultinomiaNB       | 0.876 |
| LogisticRegression | 0.843 |
| SVC                | 0.536 |
| LinearSVC          | 0.846 |
| NuSVC              | 0.842 |

##### 以信息量丰富的所有词为特征提取取方法

| 分类算法\维度            | 500   | 1000  | 1500  | 2000  | 2500  | 3000  | 3500  | 4000  | 4500  | 5000  | 5500  | 6000  | 6500  | 7000  | 7500  | 8000  | 8500  | 9000  |
| ------------------ | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| BernoulliNB        | 0.801 | 0.778 | 0.773 | 0.771 | 0.767 | 0.772 | 0.785 | 0.779 | 0.774 | 0.756 | 0.745 | 0.745 | 0.745 | 0.745 | 0.753 | 0.75  | 0.749 | 0.748 |
| MultinomiaNB       | 0.857 | 0.863 | 0.864 | 0.869 | 0.866 | 0.869 | 0.87  | 0.877 | 0.872 | 0.875 | 0.877 | 0.877 | 0.877 | 0.877 | 0.877 | 0.877 | 0.874 | 0.874 |
| LogisticRegression | 0.827 | 0.832 | 0.825 | 0.836 | 0.832 | 0.834 | 0.838 | 0.84  | 0.837 | 0.839 | 0.837 | 0.837 | 0.837 | 0.837 | 0.84  | 0.837 | 0.838 | 0.838 |
| SVC                | 0.806 | 0.742 | 0.714 | 0.688 | 0.674 | 0.664 | 0.639 | 0.61  | 0.591 | 0.584 | 0.571 | 0.571 | 0.571 | 0.571 | 0.57  | 0.565 | 0.565 | 0.565 |
| LinearSVC          | 0.826 | 0.821 | 0.815 | 0.808 | 0.814 | 0.821 | 0.818 | 0.814 | 0.813 | 0.816 | 0.815 | 0.815 | 0.815 | 0.815 | 0.813 | 0.815 | 0.822 | 0.822 |
| NuSVC              | 0.831 | 0.835 | 0.837 | 0.845 | 0.844 | 0.844 | 0.843 | 0.846 | 0.844 | 0.844 | 0.847 | 0.847 | 0.847 | 0.847 | 0.845 | 0.843 | 0.845 | 0.843 |

##### 以信息量丰富的所有词和所有双词搭配为特征选取方法

| 分类算法\维度            | 500   | 1000  | 1500  | 2000  | 2500  | 3000  | 3500  | 4000  | 4500  | 5000  | 5500  | 6000  | 6500  | 7000  | 7500  | 8000  | 8500  | 9000  |
| ------------------ | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| BernoulliNB        | 0.798 | 0.773 | 0.775 | 0.769 | 0.772 | 0.777 | 0.784 | 0.776 | 0.767 | 0.76  | 0.747 | 0.747 | 0.747 | 0.747 | 0.75  | 0.759 | 0.759 | 0.759 |
| MultinomiaNB       | 0.854 | 0.863 | 0.867 | 0.871 | 0.871 | 0.874 | 0.874 | 0.874 | 0.874 | 0.876 | 0.876 | 0.876 | 0.876 | 0.876 | 0.877 | 0.873 | 0.873 | 0.873 |
| LogisticRegression | 0.828 | 0.831 | 0.829 | 0.834 | 0.834 | 0.832 | 0.834 | 0.834 | 0.834 | 0.839 | 0.837 | 0.837 | 0.837 | 0.837 | 0.836 | 0.835 | 0.835 | 0.835 |
| SVC                | 0.806 | 0.739 | 0.712 | 0.688 | 0.671 | 0.659 | 0.633 | 0.604 | 0.595 | 0.583 | 0.565 | 0.565 | 0.565 | 0.565 | 0.565 | 0.565 | 0.565 | 0.565 |
| LinearSVC          | 0.824 | 0.807 | 0.817 | 0.812 | 0.81  | 0.818 | 0.811 | 0.809 | 0.815 | 0.813 | 0.814 | 0.814 | 0.814 | 0.814 | 0.811 | 0.811 | 0.811 | 0.811 |
| NuSVC              | 0.829 | 0.84  | 0.835 | 0.84  | 0.844 | 0.844 | 0.846 | 0.846 | 0.845 | 0.849 | 0.852 | 0.852 | 0.852 | 0.852 | 0.853 | 0.855 | 0.855 | 0.855 |

#### 3.1.5关键步骤

1. 利用python程序包中文分词工具python对语料进行分词。

   ```python
   for file_name in FileNames:
       full_file_name = os.path.join(FindPath, file_name)
       if 'utf8' in full_file_name:
           with open(full_file_name, 'r', encoding='utf-8') as pos_f:
               pos_text = pos_f.read()
               pos_text = ''.join(pos_text.split())
               # pos_text = re.sub(string.punctuation, "", pos_text)
               pos_text = re.sub("[\s+\.\!\/_,$%^*(+\"\']+|[+——！，。？、~@#￥%……&*（）～-]+", "", pos_text)
               pos_list = jieba.cut(pos_text, cut_all=False)
               pos_words.append(list(pos_list))
   ```

2. 特征提取方法

   1.  把所有词作为特征

      ```python
      def bag_of_words(words):
          return dict([(word, True) for word in words])
      ```

   2. 把双词搭配作为特征

      ```python
      def bigram(words, score_fn=BigramAssocMeasures.chi_sq, n=1000):

          bigram_finder = BigramCollocationFinder.from_words(words)  # 把文本变成双词搭配的形式
          bigrams = bigram_finder.nbest(score_fn, n)  # 使用了卡方统计的方法，选择排名前1000的双词

          return bag_of_words(bigrams)
      ```

   3. 把所有词和双词搭配一起作为特征

      ```Python
      def bigram_words(words, score_fn=BigramAssocMeasures.chi_sq, n=1000):
      
          tuple_words = []
          for i in words:
              temp = (i,)
              tuple_words.append(temp)
      
          bigram_finder = BigramCollocationFinder.from_words(words)
          bigrams = bigram_finder.nbest(score_fn, n) # 使用了卡方统计的方法，选择排名前n的双
      
          return bag_of_words(tuple_words + bigrams)  # 所有词和（信息量大的）双词搭配一起作为特征
      ```

3. 特征选择方法

   1.  计算整个语料里面所有的信息量

      ```python
      def create_word_scores():
          posWords = pickle.load(open(pos_f, 'rb'))
          negWords = pickle.load(open(neg_f, 'rb'))

          posWords = list(itertools.chain(*posWords))  # 把多维数组解链成一维数组
          negWords = list(itertools.chain(*negWords))  # 同理

          word_fd = FreqDist()  # 可统计所有词的词频
          cond_word_fd = ConditionalFreqDist()  # 可统计积极文本中的词频和消极文本中的词
          for word in posWords:
              word_fd[word] += 1
              cond_word_fd["pos"][word] += 1
          for word in negWords:
              word_fd[word] += 1
              cond_word_fd["neg"][word] += 1

          pos_word_count = cond_word_fd['pos'].N()  # 积极词的数量
          neg_word_count = cond_word_fd['neg'].N()  # 消极词的数量
          total_word_count = pos_word_count + neg_word_count

          word_scores = {}
          for word, freq in word_fd.items():
              pos_score = BigramAssocMeasures.chi_sq(cond_word_fd['pos'][word], (freq, pos_word_count),
                                                     total_word_count)  # 计算积极词的卡方统计量，这里也可以计算互信息等其它统计量
              neg_score = BigramAssocMeasures.chi_sq(cond_word_fd['neg'][word], (freq, neg_word_count),
                                                     total_word_count)  # 同理
              word_scores[word] = pos_score + neg_score  # 一个词的信息量等于积极卡方统计量加上消极卡方统计量

          return word_scores  # 包括了每个词和这个词的信息量
      ```

   2. 计算整个语料里面所有词和双词搭配的信息量

      ```Python
      def create_word_bigram_scores():
          posdata = pickle.load(open(pos_f, 'rb'))
          negdata = pickle.load(open(neg_f, 'rb'))

          posWords = list(itertools.chain(*posdata))
          negWords = list(itertools.chain(*negdata))

          bigram_finder = BigramCollocationFinder.from_words(posWords)
          posBigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 5000)
          bigram_finder = BigramCollocationFinder.from_words(negWords)
          negBigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 5000)

          pos = posWords + posBigrams  # 词和双词搭配
          neg = negWords + negBigrams

          word_fd = FreqDist()
          cond_word_fd = ConditionalFreqDist()
          for word in pos:
              word_fd[word] += 1
              cond_word_fd["pos"][word] += 1
          for word in neg:
              word_fd[word] += 1
              cond_word_fd["neg"][word] += 1

          pos_word_count = cond_word_fd['pos'].N()
          neg_word_count = cond_word_fd['neg'].N()
          total_word_count = pos_word_count + neg_word_count

          word_scores = {}
          for word, freq in word_fd.items():
              pos_score = BigramAssocMeasures.chi_sq(cond_word_fd['pos'][word], (freq, pos_word_count), total_word_count)  # 计算积极词的卡方统计量，这里也可以计算互信息等其它统计量
              neg_score = BigramAssocMeasures.chi_sq(cond_word_fd['neg'][word], (freq, neg_word_count), total_word_count)
              word_scores[word] = pos_score + neg_score

          return word_scores
      ```

   3. 根据信息量进行倒序排序，选择排名靠前的信息量的词

      ```Python
      def find_best_words(word_scores, number):
          best_vals = sorted(word_scores.items(), key=lambda w_s: w_s[1], reverse=True)[:number]  # 把词按信息量倒序排序。number是特征的维度，是可以不断调整直至最优的
          best_words = set([w for w, s in best_vals])
          return best_words
      ```

   4. 把选出的这些词作为特征（这就是选择了信息量丰富的特征）

      ```python
      def best_word_features(words):
          # load_data()
          # word_scores = create_word_bigram_scores()
          global best_words
          # best_words = find_best_words(word_scores, 7500)
          return dict([(word, True) for word in words if word in best_words])
      ```

4. 分割数据及赋予类标签

   ```python
   # 积极
   def pos_features(feature_extraction_method):
       posFeatures = []
       for i in pos_review:
           posWords = [feature_extraction_method(i), 'pos']  # 为积极文本赋予"pos"
           posFeatures.append(posWords)
       return posFeatures
   ```

# 二、需求规约



## 1.项目介绍



### 1.1项目背景

文本情感分析又称意见挖掘， 是对包含用户观点、 喜好、 情感等主观性文本进行挖掘、 分析

及判别它是一个多学科交叉的研究领域， 涉及**概率论**、 **数据统计分析**、 **计算机语言学**、 **自然语言**

**处理**、 **机器学习**、 **信息检索**、 **本体学**   ( Ontology) 等多个学科及其相关技术 。鉴于其在用户

意见挖掘、 垃圾邮件过滤及舆情分析等 多个领域具有重要的应用价值， 文本情感分析正受到国内外

众多研究机构和学者的重视。



情感分析可归纳为情感信息抽取、 情感信息分类及情感信息的检索与归纳三项层层递进的研究任 

务 。本文研究的重点是情感信息分类， 旨在将文本情感分为褒义、 贬义两类或者更细致的情感类别。

按照分析文本的粒度不同， 情感信息分类可分为**词语级** 、 **短语级** 、 **句子级** 、 **篇章级** 等几个研究层

次。

       

目前， 情感分类大致涌现出两种研究思路:  **基于情感知识** 和 **基于特征** 。前者主要是基于已有的情感词典或情感知识库 对文本中带有情感或极性的词( 或词语单元) 进行加

权求和， 而后者主要是对文本提取具有类别表征意义的 特征， 再基于这些特征使用机器学习算法进

行分类。



### 1.2项目目标

* 使用 机器学习 和 情感词典 这两种方法 分别对中文新闻类文本进行情感极性分析

* 输入一段新闻文本能够得到文本的情感极性

  

### 1.3目标人群

* 需要对已有中文文本数据进行情感分析的企业及用户
* APP中需要集成中文文本情感分析功能的开发人员
* 从事中文文本情感分析与挖掘的研究人员

  

### 1.4项目边界

本项目是一个向有中文文本情感分析需求的人员提供接口服务， 并尽可能提高服务质量的APP。

用户可以通过浏览我们的网站来体验我们的中文文本情感分析服务， 并且可以参与到我们的用户体验改善

计划中： 通过向系统机器学习方法接口传递一个已知情感极性的文本及其情感极性来不断训练我们的模型, 

同时也可以查看系统返回的分析结果向我们后台反馈错误, 错误样例被相应数据库所记录。

这样，我们可以不断修复导致用户反馈的错误的bug，以及使用日益完善的模型来不断提高我们向用户提供

的服质量。此外，需要在项目中使用中文文本情感分析功能的开发人员可以向我们申请服务接口来进一步使

用我们所提供的服务。



* #### what we can do 

  * 机器学习方法的接口，接受一个中文文本， 可得到一个正向情感极性的概率和负向情感

    的概率。

  * 基于情感词典的方法的接口， 输入一段中文文本， 可得到文本的情感极性分值 。

  * 可对 篇章级、段落级、句子级 的中文文本进行情感极性判断。

  * 基于情感词典的方法的接口，可以使用不同的情感词典对中文文本进行情感分析。

  * 基于机器学习的方法的接口，可以导入一个训练好的模型来对中文文本进行情感分析。

  * 提供了训练模型和测试准确率的接口， 方便开发者及用户测试我们算法，并汇报错误。

  * 提供了一个数据库用来记录常见的分析用语，以及分析错误的语句，便于开发者完善情感

    分析算法以及修复程序中的bug。

    



* #### what we cannot do

  * 无法识别除中文以外的其他语言的文本
  * 无法识别中文文本中的描述对象，无法得出所描述对象的情感极性值
  * 暂时无法对中文文本中蕴含的情感进行分类（喜怒哀乐等）

    









## 2.项目需求分析

### 2.1系统KAOS图



![](https://www.writebug.com/myres/static/uploads/2021/10/28/b92cf9d1032fb72716d7bb7a54d1cce4.writebug)





## 3.用例分析

### 3.1概述

* 本系统有2个参与者, 包括 **用户** , **管理员** 。 



* 用户为本系统所提供服务的使用者

  * 用户可以直接使用系统所暴露的情感分析接口向后台传递一个中文字符串，从而获得一个文本的正负向情感结果；
  * 用户也可以对系统返回的结果进行判断并反馈错误, 具体操作如下
    1. 在文本框输入一段已知情感正负向的中文文本并且提供这段文本的正负向情感信息, 来获取结果。
    2. 用户判断系统返回的情感分析结果有误, 点击文本框下方的反馈错误按钮, 反馈错误样例
    3. 系统会自动的将用户所提供的错误样例的信息插入到“待审核样例数据库” 中， 并通知管理员去审核。
    4. 管理员在审核错误样例, 系统得到每条待审核错误样例的审核结果
       1. 如果错误样例的审核结果是 : 有效,   那么这条错误样例将被记录到错误样例数据库中
    5. 被管理员审核过的待审核测试样例从待审核样例数据库中删除

  

* 管理员为本系统的管理人员。

  * 管理员也可以通过情感词典管理模块来对情感词典进行修改等操作

  * 管理员还可以审核用户反馈的错误样例，和直接访问控制系统样例数据数据库, 对系统的样例进行管理,

    以方便开发人员修复系统的漏洞, 进一步提高系统提供的服务质量

    

-----

### 3.2系统用例总图



![](https://www.writebug.com/myres/static/uploads/2021/10/28/ec15e77d6a2c15086a46d7f63c28f19f.writebug)

                                                   

																					图1- 系统用例 总图

---

### 3.3详述



![](https://www.writebug.com/myres/static/uploads/2021/10/28/af94ce413d0ed5cbb0238f5d8e630b9c.writebug)                     

&nbsp;										图2 -  分析情感文本 -  用例

                         

### 3.4父用例: _分析情感文本_

#### 描述对象

* 分析情感文本

#### 标识符

* UC00

#### 说明

* 用户使用系统的官方网站上提供的接口输入文本信息, 或使用系统所提供的url接口进行post中文字符串

       来获取情感分析结果

#### 参与者

* 用户

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 网络连接成功
* 用户访问了我们的网站
* 用户在开发应用中正确的使用了我们所提供的URL, 以正确的方式进行了Http请求

#### 后置条件

* 用户所访问的我们网站的页面上显示了,用户所提交文本的情感的正负向信息
* 用户的目标应用将接受到一个表示其所提交的文本的情感的正负向信息

#### 被扩展的用例

* 无

#### 被包含的用例

* 无

#### 可选操作流程



------

### 3.5子用例: _使用机器学习方法_

#### 描述对象

* 使用机器学习方法

#### 标识符

* UC01

#### 说明

* 用户使用系统的官方网站上提供的"使用情感词典方法的文本情感极值分析接口"输入文本信息
* 用户使用系统所提供的"情感词典的文本情感极值分析接口"的URL进行post字符串
* 用户收到所提交的中文字符串在进行情感分析后的结果

#### 参与者

* 用户

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 网络连接成功
* 使用访问网站的方式:
  * 用户访问了我们的网站
  * 用户在机器学习栏目的文本输入框内输入了一段中文字符串
* 使用发送Http 请求的方式
  * 用户的网络请求代码里正确使用了我们所提供的URL
  * 用户使用Post方式以我们提供的URL来提交一个中文字符串

#### 后置条件

* 用户所访问的我们网站的页面上显示了,用户所提交文本的情感的正负向信息
* 用户的目标应用将接受到一个表示其所提交的文本的情感的正负向信息

#### 被扩展的用例

* 无

#### 被包含的用例

* 无

#### 基本操作流程

* 使用访问网页的方式

  1. 用户打开我们网站 
  2. 用户在网站的情感词典接口栏目相应的文本输出栏内输入所要分析的中文文本

* 使用URL发送Http请求的方式

  1. 在应用程序中添加 网络请求 方面的代码, 使用post的方式向

     传递一个中文字符串

#### 可选操作流程

* 滚动鼠标滑轮

* 用户可以在情感词典栏目输入需要进行情感分析的中文字符串来获得情感分析结果

  

-------



### 3.6子用例: _使用情感词典方法_

#### 描述对象

* 使用情感词典方法

#### 标识符

* UC02

#### 说明

* 用户使用系统的官方网站上提供的"使用机器学习方法的文本情感极值分析接口"输入文本信息
* 用户使用系统所提供的"使用机器学习方法的文本情感极值分析接口"的URL进行post字符串
* 用户收到所提交的中文字符串在进行情感分析后的结果

#### 参与者

* 用户

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 网络连接成功
* 使用访问网站的方式:
  * 用户访问了我们的网站
  * 用户在机器学习栏目的文本输入框内输入了一段中文字符串
* 使用发送Http 请求的方式
  * 用户的网络请求代码里正确使用了我们所提供的URL
  * 用户使用Post方式以我们提供的URL来提交一个中文字符串

#### 后置条件

* 用户所访问的我们网站的页面上显示了,用户所提交文本的情感的正负向信息
* 用户的目标应用将接受到一个表示其所提交的文本的情感的正负向信息

#### 被扩展的用例

* 无

#### 被包含的用例

* 使用知网词典
* 使用大连理工词典
* 使用NTUSD词典
* 使用清华李建军词典
* 使用情感极值词典

#### 基本操作流程

* 使用访问网页的方式

  1. 用户打开我们的网站
  2. 用户在网站的机器学习接口栏目相应的文本输出栏内输入所要分析的中文文本

* 使用URL发送Http请求的方式

  1. 在应用程序中添加 网络请求 方面的代码, 使用post的方式向

     传递一个中文字符串

#### 可选操作流程

* 用户可以点击反馈错误按钮反馈错误




----



### 3.7被包含用例: _使用知网词典_

#### 描述对象

* 使用知网词典

#### 标识符

 * UC03

#### 说明

* 用户在使用情感词典情感分析接口的时候可以选择使用的词典为知网词典来进行情感分析

#### 参与者

* 用户

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 网络连接成功
* 用户通过访问我们的网页或使用Http请求的方法来与我们的接口交互
* 用户选择了使用情感词典方法的接口

#### 后置条件

* 用户所访问的我们网站的页面上显示了, 用户所提交文本的情感的正负向信息
* or
* 用户的目标应用将接受到一个表示其所提交的文本的情感的正负向信息

#### 被扩展的用例

* 无

#### 被包含的用例

* 无

#### 基本操作流程

* 使用访问网页的方式
  1. 用户打开我们服务提供网页 
  2. 用户在情感词典方法接口的左上角下拉框中选择使用知网情感词典
  3. 用户在网站的接口栏目相应的文本输出栏内输入所要分析的中文文本
* 使用URL发送Http请求的方式
  1. 在应用程序中添加 网络请求 方面的代码, 使用post的方式向传递一个中文字符串

#### 可选操作流程

* 用户可以点击反馈错误按钮反馈错误




----

### 3.8被包含用例: _使用大连理工词典_

#### 描述对象

* 使用大连理工词典

#### 标识符

* UC04

#### 说明

* 用户在使用情感词典情感分析接口的时候可以选择使用的词典为大连理工词典来进行情感分析

#### 参与者

* 用户

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 网络连接成功
* 用户通过访问我们的网页或使用Http请求的方法来与我们的接口交互
* 用户选择了使用情感词典方法的接口

#### 后置条件

* 用户所访问的我们网站的页面上显示了, 用户所提交文本的情感的正负向信息
* or
* 用户的目标应用将接受到一个表示其所提交的文本的情感的正负向信息

#### 被扩展的用例

* 无

#### 被包含的用例

* 无

#### 基本操作流程

* 使用访问网页的方式
  1. 用户打开我们服务提供网页 
  2. 用户在情感词典方法接口的左上角下拉框中选择使用大连理工情感词典
  3. 用户在网站的接口栏目相应的文本输出栏内输入所要分析的中文文本
* 使用URL发送Http请求的方式
  1. 在应用程序中添加 网络请求 方面的代码, 使用post的方式向传递一个中文字符串

#### 可选操作流程

* 用户可以点击反馈错误按钮反馈错误




---

### 3.9被包含用例: _使用 NTUSD词典_

#### 描述对象

* 使用NTUSD词典

#### 标识符

* UC05

#### 说明

* 用户在使用情感词典情感分析接口的时候可以选择使用的词典为NTUSD词典来进行情感分析

#### 参与者

* 用户

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 网络连接成功
* 用户通过访问我们的网页或使用Http请求的方法来与我们的接口交互
* 用户选择了使用情感词典方法的接口

#### 后置条件

* 用户所访问的我们网站的页面上显示了, 用户所提交文本的情感的正负向信息
* or
* 用户的目标应用将接受到一个表示其所提交的文本的情感的正负向信息

#### 被扩展的用例

* 无

#### 被包含的用例

* 无

#### 基本操作流程

* 使用访问网页的方式
  1. 用户打开我们服务提供网页 
  2. 用户在情感词典方法接口的左上角下拉框中选择使用NTUSD词典
  3. 用户在网站的接口栏目相应的文本输出栏内输入所要分析的中文文本
* 使用URL发送Http请求的方式
  1. 在应用程序中添加 网络请求 方面的代码, 使用post的方式向传递一个中文字符串

#### 可选操作流程

* 用户可以点击反馈错误按钮反馈错误


----

### 3.10被包含用例: _使用清华李建军词典_

#### 描述对象

* 使用清华李建军词典

#### 标识符

* UC06

#### 说明

* 用户在使用情感词典情感分析接口的时候可以选择使用的词典为清华李建军词典来进行情感分析

#### 参与者

* 用户

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 网络连接成功
* 用户通过访问我们的网页或使用Http请求的方法来与我们的接口交互
* 用户选择了使用情感词典方法的接口

#### 后置条件

* 用户所访问的我们网站的页面上显示了, 用户所提交文本的情感的正负向信息
* or
* 用户的目标应用将接受到一个表示其所提交的文本的情感的正负向信息

#### 被扩展的用例

* 无

#### 被包含的用例

* 无

#### 基本操作流程

* 使用访问网页的方式
  1. 用户打开我们服务提供网页 
  2. 用户在情感词典方法接口的左上角下拉框中选择使用清华李建军情感词典
  3. 用户在网站的接口栏目相应的文本输出栏内输入所要分析的中文文本
* 使用URL发送Http请求的方式
  1. 在应用程序中添加 网络请求 方面的代码, 使用post的方式向传递一个中文字符串

#### 可选操作流程

* 用户可以点击反馈错误按钮反馈错误


---

### 3.11被包含用例: _使用情感极值词典_

#### 描述对象

* 使用情感极值词典

#### 标识符

* UC07

#### 说明

* 用户在使用情感词典情感分析接口的时候可以选择使用的词典为情感极值词典来进行情感分析

#### 参与者

* 用户

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 网络连接成功
* 用户通过访问我们的网页或使用Http请求的方法来与我们的接口交互
* 用户选择了使用情感词典方法的接口

#### 后置条件

* 用户所访问的我们网站的页面上显示了, 用户所提交文本的情感的正负向信息
* or
* 用户的目标应用将接受到一个表示其所提交的文本的情感的正负向信息

#### 被扩展的用例

* 无

#### 被包含的用例

* 无

#### 基本操作流程

* 使用访问网页的方式
  1. 用户打开我们服务提供网页 
  2. 用户在情感词典方法接口的左上角下拉框中选择使用情感极值情感词典
  3. 用户在网站的接口栏目相应的文本输出栏内输入所要分析的中文文本
* 使用URL发送Http请求的方式
  1. 在应用程序中添加 网络请求 方面的代码, 使用post的方式向传递一个中文字符串

#### 可选操作流程

* 用户可以点击反馈错误按钮反馈错误




----



![](https://www.writebug.com/myres/static/uploads/2021/10/28/2c125d83135eeca483fe632ea9fe0d0e.writebug)

                                                                        图 5 - 反馈错误样例

### 3.12用例: _反馈错误样例_

#### 描述对象

* 反馈错误样例

#### 标识符

* UC08

#### 说明

* 用户访问系统提供的网站, 使用测试接口, 在文本输入框里输入一个中文文本， 如果系统返回的结果不符合要求，则可以通过点击下方的反馈错误按钮反馈错误


#### 参与者

* 用户

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 用户进入了系统提供的网站。

#### 后置条件

* 系统将受到用户反馈的错误样例：
* 系统将用户反馈的样例标记为待审核样例

#### 被扩展的用例

* 无

#### 被包含的用例

* 录入待审核测试样例

#### 基本操作流程

1. 用户访问系统提供的官方网站, 任意一个文本输入框内输入一段已知情感极性的中文文本
2. 系统返回给用户页面对该文本进行情感分析的结果
3. 用户审核这个结果有误，可以点击文本输入框下的”反馈错误“， 向系统反馈错误样例
4. 系统收到错误样例后， 将通知管理员对该测试样例进行审核
5. 管理员审核通过后将通知用户页面反馈已通过审核

#### 可选操作流程

* 无




-----



![](https://www.writebug.com/myres/static/uploads/2021/10/28/aa26810898a56c5a631dea6d903ea96b.writebug)

                                                                 图 6 - 管理情感词典用例

### 3.13主用例:  _管理情感词典_

#### 描述对象

* 情感词典管理

#### 标识符

* UC09

#### 说明

* 管理员通过情感词典管理用例对系统内部的情感词典进行调整， 从而改变系统所提供的基于词典的情感分析

  的接口服务的服务质量。

#### 参与者

* 管理员

#### 频度

* 中

#### 状态

* 通过

#### 前置条件

* 管理员登入情感词典管理页面

#### 后置条件

* 情感词典得到调整。

#### 被扩展的用例

* 无

#### 被包含的用例

* 添加词典


* 删除词典
* 修改词典
* 导入导出词典

#### 基本操作流程

1. 管理员登入情感词典管理页面。
2. 管理员在该页面的不同栏目进行系统所提供的可选操作。
3. 管理员在页面点击提交按钮。
4. 管理员在确认框内点击确认按钮。
5. 系统执行管理员的提交的操作命令。

#### 可选操作流程

* 管理员可以在提交前可以修改操作
* 管理员可以点击确认框的取消按钮取消本次操作






--------



                                                ![](https://www.writebug.com/myres/static/uploads/2021/10/28/30d14794bc920ca534b61d428d8c10e3.writebug)               


                                                   





### 3.14用例:  _管理测试样例_ 

#### 描述对象

* 样例管理

#### 标识符

* UC10

#### 说明

* 管理员通过样例管理用例可以对系统的样例进行管理
* 系统的样例分为:
  * 测试样例
  * 待审核样例
  * 程序出错样例

#### 参与者

* 管理员

#### 频度

* 中

#### 状态

* 通过

#### 前置条件

* 管理员管理员进入了系统页面

#### 后置条件

* 系统样例得到了管理

#### 被扩展的用例

* 无

#### 被包含的用例

* 无

#### 被继承的用例

* 测试样例管理
* 待审核样例管理
* 程序出错样例管理

#### 基本操作流程

* 管理员进入系统管理页面
* 管理员在页面选择一个样例管理页面并进入
* 管理员根据页面所暴露的功能操作交互接口进行一系列操作
* 管理人点击页面的提交按钮, 并确认操作

#### 可选操作流程

* 管理员在提交后可以点击取消按钮来取消操作




---



![](https://www.writebug.com/myres/static/uploads/2021/10/28/9079ce786571eca7cb9a7962ddd907fd.writebug)

### 3.15用例:  _审核错误样例_

#### 描述对象

* 样例管理

#### 标识符

* UC11

#### 说明

* 管理员可以通过审核错误样例, 来向系统添加有效的错误样例, 以间接提高系统的准确度

**参与者** 

* 管理员

#### 频度

* 高

#### 状态

* 通过

#### 前置条件

* 管理员管理员进入了管理系统

#### 后置条件

* 待审核错误样例得到审核

#### 被扩展的用例

* 无

#### 被包含的用例

* 无

#### 基本操作流程

* 管理员进入系统待审核样例管理页面
* 页面显示一列未审核的错误样例
* 管理员点击每条样例的text域查看错误样例, 结合错误样例给出的情感极值判断错误样例是否有效
  * 如果有效 : 管理员点击样例右侧的有效选项
  * 如果无效 : 管理员点击样例右侧的无效选项
* 被审核的错误样例从待审核错误样例中删除
* 被判定有效的错误样例录入错误样例数据库

#### 可选操作流程

* 管理员可以以随意的顺序审核页面显示的错误样例





   # 二、消极

   def neg_features(feature_extraction_method):

```python
   negFeatures = []
   for j in neg_review:
       negWords = [feature_extraction_method(j), 'neg']  # 为消极文本赋予"neg"
       negFeatures.append(negWords)
   return negFeatures
```
   ```python

5. 使用训练集用不同的分类算法训练分类器，用分类器对开发测试集里面的数据进行分类，给出分类预测的标签，对比分类标签和人工标注的差异，计算出准确度

   ```python
   def score(classifier):
       classifier = nltk.SklearnClassifier(classifier)  # 在nltk 中使用scikit-learn的接口
       classifier.train(train)  #训练分类器

       pred = classifier.classify_many(dev)  # 对开发测试集的数据进行分类，给出预测的标签
       return accuracy_score(tag_dev, pred)  # 对比分类预测结果和人工标注的正确结果，给出分类器准确度


   def try_diffirent_classifiers():

       results = list()
       results.append(score(BernoulliNB()))
       results.append(score(MultinomialNB()))
       results.append(score(LogisticRegression()))
       results.append(score(SVC()))
       results.append(score(LinearSVC()))
       results.append(score(NuSVC()))

       return results
   ```

6. 选择准确度最高的分类算法、特征提取方法、维度得到的分类器并存储

   ```python
   def store_classifier():
       load_data()
       word_scores = create_word_bigram_scores()
       global best_words
       best_words = find_best_words(word_scores, 7500)
   
       posFeatures = pos_features(best_word_features)
       negFeatures = neg_features(best_word_features)
   
       trainSet = posFeatures + negFeatures
   
       MultinomialNB_classifier = SklearnClassifier(MultinomialNB())
       MultinomialNB_classifier.train(trainSet)
       pickle.dump(MultinomialNB_classifier, open('../out/classifier.pkl', 'wb'))
   ```

   


## 1.情感词典算法

我们已知: 

* 中文文本以字符串的方式传进系统
* 段落与段落之间使用换行符来划分
* 句子之间以 " 。，？！" 来划分
* 短句子，短句子之间以 “ ， ” 来划分

#### 1.1基本思想

* 一个中文文本的情感值由构成它的所有的段落的情感值所决定
* 一个段落的情感值由构成它的所有的长句子决定
* 一个长句子的情感值由构成它的所有短句子的情感值决定
* 一个短句子的情感值由构成它的所有词语的情感值决定
* 将组成一个短句子的所有词语的情感值查找出来, 记录于一个列表中, 将一定的算法施加于这个列表, 得到短句子的情感值
* 将组成一个长句子的所有短句子的情感值记录于一个列表中, 将一定的算法施加于这个列表, 得到长句子的情感值
* 将组成一个段落的所有长句子的情感值记录于一个列表中,  将一定的算法施加于这个列表,  得到段落的情感值
* 将组成一个篇章的所有段落的情感值记录于一个列表中,  将一定的算法施加于这个列表,  得到篇章的情感值



#### 1.2算法流程: 

1. 将一个中文文本转换为一个有短句子字符串组成列表
2. 对每一个短句子字符串进行如下操作：
   1. 使用 jieba 分词系统将一个短句子转换成 词语, 词性对 的列表
   2. 使用词语的词性筛选出潜在的情感词语, 
   3. 在已有的情感词典中查找这些潜在的情感词语
   4. 所查找的情感词语的情感词语分类 以及 它的情感值组合成一个词典并记录到一个列表中
   5. 使用相应的算法处理这个列表, 得出这个小句子的情感极值
3. 将一个中文文本中的所有短句子的情感极值记录在一个列表中
4. 使用相应的算法处理这个列表, 得出整个中文文本的情感极值


![](https://www.writebug.com/myres/static/uploads/2021/10/28/4fbf47dfe80f4b690ef8ea3f589c9b88.writebug)

#### 1.3算法特性

1. 算法准确率基于分词的准确率, 以及情感词典的准确率
2. 对句式简单的句子的识别准确率高
3. 对复杂句子的分析依赖于复杂的文本处理算法 



#### 1.4关键代码

1. 加载情感词典

   ```python
   #-----------------------------------------------------------------------
   #   初始化词典 , 加载自定义jieba词典
   #   para_in : dic_kind 词典类型
   #             1.    知网
   #             2.    大连理工
   #             3.    NTUSD
   #             4.    清华李建军
   #             5.    清华情感词极值词典
   #             else  None
   #   para_out: 无
   #-----------------------------------------------------------------------
   def __init_dic__(dic_kind):
       global ext_dic
       jieba.load_userdict(dic_root_path + 'create_by_huzehao/jieba_dic.txt')
       __path__ = dic_root_path + "zhiwang\\"
       ext_dic = Modules.load_dic.load_ext_dic(__path__, "extent_Lv_")  # 初始化程度副词词典
       __init__no_word_list()
       if dic_kind == 1:               #知网
           __init_zhiwang_dic__()
       elif dic_kind == 2:             #大连理工
           __init_dllg_dic__()
       elif dic_kind == 3:             #NTUSD
           __init_ntusd_dic__()
       elif dic_kind == 4:             #清华大学 李建军
           __init_tsinghua_dic__()
       elif dic_kind == 5:             #情感极值词典
           __init_extreme_dic__()
       else:
           return None
   ```



2. 得出词语详细信息

   ```   python
   #-----------------------------------------------------------------------
   #给出一个中文词语, 及其词性, 返回一个字典, 里面包含 词语 词性 分数 情感词类型
   #   eg: {'n': '恶劣', 'k': 'a', 's': -1, 'p': 'neg'}
   #         n:词语名     k: 词性   s:分数    p: 属性
   #   para_in :  word       词语
   #   para_in :  kind       词性
   #   para_in :  dic_kind   字典类型
   #   para_in :  All        是否为全模式(默认为False)
   #                         True   :对所有传入的词语均返回一个详细信息
   #                         False  :只对词性在 sense_word_kind_set 里的词返回一个详细信息
   #   para_out:  dic        描述一个词语的详细信息
   #-----------------------------------------------------------------------
   def find_word_info(word, kind, dic_kind, All = True):
       dic = {}
       def __setdic__(k, s, p = None):
           dic['n'] = word                   #word
           dic['k'] = k                      #kind
           dic['s'] = s                      #score
           dic['p'] = p                      #property

       def __common__(pos_dic, neg_dic):     #如果词语是正面情感词或负面情感词的时候, 进行该操作
           score = __getScore__(pos_dic, word)
           if score != 0:
               __setdic__(kind, score, 'pos')
           else:
               score = __getScore__(neg_dic, word)
               if score != 0:
                   __setdic__(kind, score, 'neg')
               else:  # 有意义的词被遗漏了
                   __setdic__(kind, score)
                   ignoredWordList.write("{} {} {}\n".format(word, kind, score))

       if word in no_word_set:
           __setdic__('no', None, None)
       elif  kind in sense_word_kind_set:
           score =  __getScore__(ext_dic, word)
           if score != 0:
               __setdic__(kind, score, 'ext')
           else:
               if dic_kind == 1:       #知网
                   __common__(zhiwang_pos_sen_dic, zhiwang_neg_sen_dic)

               elif dic_kind == 2:     #大连理工
                   pass

               elif dic_kind == 3:     #ntusd
                   __common__(ntusd_pos_dic,ntusd_neg_dic)

               elif dic_kind == 4:     #清华 李建军
                   __common__(tsinghua_pos_dic, tsinghua_neg_dic)

               elif dic_kind == 5:     #情感极值词典
                   score = __getScore__(word_extreme_dic, word)
                   if score > 0:
                       __setdic__(kind, score, "pos")
                   elif score < 0:
                       __setdic__(kind, score, "neg")
                   else:              #情感词语遗漏了
                       ignoredWordList.write("{} {} {}\n".format(word, kind, score))

       if len(dic) > 0:
           return dic
       elif All:
           __setdic__(kind, 0, None)
           return dic
       else: return None

   ```

3. 计算短句子情感值

   ```python
   #-----------------------------------------------------------------------
   #   para_in :tiny_sentence
   #   para_in :
   #	para_in : 
   #   para_out: score
   #-----------------------------------------------------------------------
   def _get_group_score(tiny_sentence,group = [{}], stream = None):
       if len(group) > 0:
           stack = []
           score = None
           score_item = None
           pair = getCommentPair(tiny_sentence,group)
           if pair != None:
               score_item = conn.execute('select s from polysemy where a = ? and n = ?', pair).fetchone()
               if score_item != None:
                   score = score_item[0]
                   stack.append(score)
                   for item in group:
                       if item.get('k') == 'no':
                           stack.append(-1)
                       elif item.get('k') == 'ext':
                           stack.append(item.get('s'))
                   return  __CaculateScoreOfGroup__(stack, False), stack, pair
           #else:
           score, stack = get_group_score(group)
           return score, stack, pair
       return 0, None
   ```

4. 获取整个中文文本的情感值

   ```
   #-----------------------------------------------------------------------
   #                               暴露接口
   #   para_in : text      文件内容    字符串
   #   para_in : dic_kind  词典类型    整数值
   #             1: 知网
   #             2: 大连理工
   #             3: ntusd
   #             4:李建军
   #             5:极值词典
   #   para_out: score     文本情感值
   #-----------------------------------------------------------------------
   def getScoreFromString(text, dic_kind):
       __init_dic__(dic_kind)
       pgen = get_paragraph(text)
       ggen = get_group(pgen)
       _score_sum_ = 0
       if dic_kind == 4:
           _score_sum_ = _text_processing_(text)
       else:
           for group in ggen:
               wordList = splict_group_into_list(group, dic_kind)
               score, stack = _get_group_score(wordList)
               _score_sum_ += score
               #print(group, score, stack, wordList)
       return _score_sum_
   ```

   

#### 1.5使用词典

* 大连理工情感词典
* 台湾大学NTUSD情感词典
* 清华大学李中军情感词典
* 知网Hownet情感词典
* 否定词词典
* 程度副词词典



## 2.测试语料

* 谭松波--酒店评论语料

## 3.测试结果

|             | 负    | 正    | 零    | 准确率   |
| ----------- | ---- | ---- | ---- | ----- |
| 1000条负向情感文本 | 742  | 182  | 73   | 74.2% |
| 3000条负向情感   | 2145 | 607  | 248  | 71.5% |
| 1000条正向情感文本 | 158  | 745  | 97   | 74.5% |





## 4.类设计

![](https://www.writebug.com/myres/static/uploads/2021/10/28/f4525b7da5ee80bee4de34721b383240.writebug)

------



![](https://www.writebug.com/myres/static/uploads/2021/10/28/3f332e11c398d4cace6c0d622536b89a.writebug)

### 4.1TestSample

**测试样例** 

- class TestSample

#### 4.1.1Fields

| Field             | Description |
| ----------------- | ----------- |
| _id               | 测试样例的ID     |
| _text             | 测试样例的文本     |
| _emotion_extremum | 测试样例的情感极值   |

#### 4.1.2构造函数

> def __ init __ (self, id, text, emotion_extremum)

通过 id, text, emotion_extremum 来构造一个测试样例

**参数** 

* _id 
* _text
* _emotion_extremum

#### 4.1.3方法

> getId

* def getId()

获取测试样例的ID

**returns**

* 测试样例的id

**parameters**

none

**throws**

GeneralExpection



> getId

* def getId(id)

给测试样例设置id

**returns**

* none

**parameters**

* id

**throws**

GeneralExpection





> getText

* def getText()
* 获取测试样例的中文文本

**returns**

* none

**parameters**

* none

**throws**

* GeneralExpection



> setText

* def setText()

设置测试样例的文本

**returns**

* none

**parameters**

* text

**throws**

* GeneralExpection



> getEmotionExtremum()

* def getEmotionExtremum()

获取测试样例的情感极值

**returns**

* _emotion_extremum

**parameters**

* none

**throws**

* GeneralExpection



> setEmotionExtremum()

* def setEmotionExtremum(extremum)

设置测试样例的情感极值

**returns**

* none

**parameters**

* extremum

**throws**

GeneralExpection





### 4.2WaitingSample

**测试样例** 

* class WaitingSample(TestSample)

继承于TestSample

#### 4.2.1Fields

| Field             | Description |
| ----------------- | ----------- |
| _id               | 测试样例的ID     |
| _text             | 测试样例的文本     |
| _emotion_extremum | 测试样例的情感极值   |
| _verify_result    | 审核结果        |

#### 4.2.2构造函数

> def __ init __ (self, id, text, emotion_extremum, check_result)

通过 id, text, emotion_extremum,check_result 来构造一个测试样例

**参数** 

* id 
* text
* emotion_extremum

#### 4.2.3方法

> getId

* def getId()

获取测试样例的ID

**returns**

* 测试样例的id

**parameters**

none

**throws**

GeneralExpection



> getId

* def getId()

获取测试样例的ID

**returns**

* 测试样例的id

**parameters**

none

**throws**

GeneralExpection



> getId

* def getId(id)

给测试样例设置id

**returns**

* none

**parameters**

* id

**throws**

GeneralExpection





> getText

* def getText()
* 获取测试样例的中文文本

**returns**

* none

**parameters**

* none

**throws**

* GeneralExpection



> setText

* def setText()

设置测试样例的文本

**returns**

* none

**parameters**

* text

**throws**

* GeneralExpection



> getEmotionExtremum()

* def getEmotionExtremum()

获取测试样例的情感极值

**returns**

* _emotion_extremum

**parameters**

* none

**throws**

* GeneralExpection



> setEmotionExtremum()

* def setEmotionExtremum(extremum)

设置测试样例的情感极值

**returns**

* none

**parameters**

* extremum

**throws**

GeneralExpection



> getVerifyResult()

* def getVerifyResult()
* 获取审核结果

**returns**

* _verify_result

**parameters**

* none

**throws**

GeneralExpection



> setVerifyResult()

* def setVerifyResult(verify_result)
* 获取审核结果

**returns**

* none

**parameters**

* none

**throws**

GeneralExpection



### 4.3CorrectSample

**测试样例** 

* class CorrectSample(TestSample)

继承于TestSample

#### 4.3.1Fields

| Field             | Description |
| ----------------- | ----------- |
| _id               | 测试样例的ID     |
| _text             | 测试样例的文本     |
| _emotion_extremum | 测试样例的情感极值   |
| _test_result      | 测试结果        |

#### 4.3.2构造函数

> def __ init __ (self, id, text, emotion_extremum, test_result)

通过 id, text, emotion_extremum, test_result 来构造一个测试样例

**参数** 

* _id 
* _text
* _emotion_extremum
* _test_result

#### 4.3.3方法

> getId

* def getId()

获取测试样例的ID

**returns**

* _id

**parameters**

none

**throws**

GeneralExpection



> getText

* def getText()

获取测试样例的文本

**returns**

* _text

**parameters**

* none

**throws**

* GeneralExpection



> getEmotionExtremum()

* def getEmotionExtremum()

获取测试样例的情感极值

**returns**

emotion_extremum

**parameters**

none

**throws**

GeneralExpection



> getTestResult()

* def getTestResult()

获取测试结果

**returns**

* _test_result

**parameters**

* none

**throws**

* GeneralExpection







### 4.4EffectiveSample

**测试样例** 

* class EffectiveSample(TestSample)

继承于TestSample

#### 4.4.1Fields

| Field              | Description |
| ------------------ | ----------- |
| _id                | 测试样例的ID     |
| _text              | 测试样例的文本     |
| _emotion_extremum  | 测试样例的情感极值   |
| _error_type        | 程序出错原因      |
| _error_information | 测试时的中间信息    |

#### 4.4.2构造函数

> def __ init __ (self, id, text, emotion_extremum, error_type, error_information)

通过 id, text, emotion_extremum, test_result, error_type, error_information来构造一个测试样例

**参数** 

* _id 
* _text
* _emotion_extremum
* _error_type
* _error_information

#### 4.4.3方法

> getId

* def getId()

获取测试样例的ID

**returns**

* 测试样例的id

**parameters**

none

**throws**

GeneralExpection



> getText

* def getText()

Get the student name.

**returns**

the student name

**parameters**

none

**throws**

GeneralExpection



> getEmotionExtremum()

* def getEmotionExtremum()

获取测试样例的情感极值

**returns**

emotion_extremum

**parameters**

none

**throws**

GeneralExpection



> getTestResult()

* def getTestResult()

获取审核结果

**returns**

check_result

**parameters**

none

**throws**

GeneralExpection



> getErrorType()

* def getErrorType()

获取审核结果

**returns**

check_result

**parameters**

none

**throws**

GeneralExpection



> setErrorType()

* def setErrorType(error_type)

获取审核结果

**returns**

error_type

**parameters**

* 

**throws**

GeneralExpection





![](https://www.writebug.com/myres/static/uploads/2021/10/28/8a2be31845df6b7f91abbc6b758ac634.writebug)



# 五、概要设计规约

## 1.Prototype Design (原型设计)

![](https://www.writebug.com/myres/static/uploads/2021/10/28/3120f4313b43a199fb4e6e71b300b3b9.writebug)

## 2.Business Architecture (业务架构)

![](https://www.writebug.com/myres/static/uploads/2021/10/28/6b5c7b0636fbe098d61989183bd3f079.writebug)

## 3.Technology Architecture (技术架构)

![](https://www.writebug.com/myres/static/uploads/2021/10/28/b454e8d097621f5266873fb8d7b36ad5.writebug)

## 4.Deployment Topology (部署结构)

![](https://www.writebug.com/myres/static/uploads/2021/10/28/3e3253d8f8f430d0308914f2a2ec4df0.writebug)



## 5.数据建模

项目使用的是mongodb ,  是 nosql 数据库,  不是传统关系型数据库,  所以没有E-R图



### 5.1数据库设计

本系统使用的mongodb 数据库, 主要存储了 **情感词典**、**测试样例**等方面数据



#### 情感词典

* 情感词典分为 主情感词典 和 分情感词典

* 一个主情感词典由一至多个分情感词典组成

* 分词典的条目数有一定限制, 在3000以内

* 示例:

  ``` 
  {
  	主词典名: "知网Hownet词典",

  	分词典集合 : [ "程度副词词典", "否定词词典", "正向情感词典", "负向情感词典"]
  }
  ```

* 设计

  * 一个主词典对应一个collection

  * 一个分词典对应一个collection中的一个document

  * 分词典词条数限制为 5000

  * 分词典中的词条 分页 存储, 每100 一页, 共有50页

  * 分词典描述表 : 

    | field             | Type   | description    |
    | ----------------- | ------ | -------------- |
    | _id               |        |                |
    | part_dic_name     | string | 分词典名称     |
    | author            | string | 创建人         |
    | create_time       | Date   | 创建时间       |
    | last_changed_time | Date   | 最近修改时间   |
    | page_1            | []     | 文档列表       |
    | page_2            | []     | 文档列表       |
    | ...               |        | 一共由50个page |
    | page_50           | []     | 文档列表       |

  * 示例 : 知网Hownet情感词典 ( 最外层 "{}" 表示这是一个collection )

    ```json
    {
    	{
    		_id : 0,
    		main_dic_name : "知网Hownet情感词典" ,
    		author : "huzehao",
    		create_time :  ISODate("2013-02-22T03:03:37.312Z"),
    		last_changed_time :  ISODate("2013-02-22T03:03:37.312Z"),
    		part_dic : [ "程度副词词典", "否定词词典", "正向情感词典", "负向情感词典"]
    	}
    	
    	{
    		_id : 1,
    		part_dic_name : "程度副词词典",
    		author : "huzehao",
    		create_time : ISODate("2013-02-22T03:03:37.312Z"),
    		last_changed_time : ISODate("2013-02-22T03:03:37.312Z"),
    		page_1 : [{},{},...,{}],
    		page_2 : [{},{},...,{}],
    		...
    		page_50 : [{},{},...,{}]
    	}
    	
    	{
    		_id : 1,
    		part_dic_name : "否定词词典",
    		author : "huzehao",
    		create_time : ISODate("2013-02-22T03:03:37.312Z"),
    		last_changed_time : ISODate("2013-02-22T03:03:37.312Z"),
    		page_1 : [{},{},..,{}],
    		page_2 : [],
    		...
    		page_50 : []
    	}
    	...
    }
    ```




#### 测试样例

* 样例分为 :

  * 待审核样例 ( 未被管理员审核 ) 

  * 已审核样例 : 

    * 无效样例 ( 被管理员否决的样例 )
    * 有效样例 ( 被管理员认可的样例 ) 
      * 测出程序错误的样例 ; 
        * 可以对程序出错的原因进行归纳, 分组
      * 未测出程序错误的样例 ; 

  

* 样例包含两个字段 : 

  * 情感极性  :   正向 或 负向 ; 
  * 文本 :  中文字符串 ; 

* 设计 : 

  * 待审核样例存放在一个 collection 中 ;

  * 有效样例存放在一个collection 中 ;

  * 测出程序出错的样例和出错原因分组放在一个collection 中 ; 

  * 样例用一个 document 表示 ; 

  * 字段设计 : 

    1. waiting_test_sample  ( 待测试样例 )

       | Field            | Type    | Description                                  |
       | ---------------- | ------- | -------------------------------------------- |
       | _id              | integer | 待测试样例ID                                 |
       | emotion_extremum | integer | 待测试样例文本情感极值: 1为正, -1为负        |
       | text             | String  | 待测试样例文本                               |
       | verify_result    | Integer | 审核结果 : 1 : 有效 ; -1 : 无效 ; 0 : 未审核 |

       ```json
       {
       	{
       		_id : 0
       		emo_extremum : 1,
       		text : "你好漂亮呀!",
       		verify_result : 0
       	}
       	
       	{
       		_id : 1
       		emo_extremum : 1,
       		text : "你好可爱呀!",
       		verify_result : 0
       	}
       	...
       	
       }
       ```

       

    2. correct_test_sample ( 管理员认可有效的样例 )

       | Field            | Type    | Description                                                  |
       | ---------------- | ------- | ------------------------------------------------------------ |
       | _id              | integer | 待测试样例ID                                                 |
       | emotion_extremum | integer | 待测试样例文本情感极值: 1为正, -1为负                        |
       | text             | String  | 待测试样例文本                                               |
       | test_result      | Integer | 测试结果 : 1 : 测出了系统的漏洞 ; -1 : 没有测出系统的漏洞 ; 0 : 未测试 |

       ```json
       {
       	{
       		_id : 0
       		emo_extremum : 1,
       		text : "你好漂亮呀!",
       		test_result : 0
       	}
       	
       	{
       		_id : 1
       		emo_extremum : 1,
       		text : "你好可爱呀!",
       		test_result : 0
       	}
       	...
       	
       }
       ```

       

    3. effective_test_sample ( 测出了程序漏洞的样例 )

       | Field            | Type    | Description                                                  |
       | ---------------- | ------- | ------------------------------------------------------------ |
       | _id              | Integer | 文档表示ID                                                   |
       | emotion_extremum | Integer | 情感极值 :  -1 为负向情感 ; 1 为正向情感                     |
       | text             | String  | 中文文本                                                     |
       | test_information | doc     | 测试过程中的中间信息示例 :  ( 最外层 "{}" 表示 这是一个 collection ) |
       | error_type       | list    | 程序出错的原因                                               |

       ```json
       {
       	{
       		_id : 0
       		emo_extremum : 1,
       		text : "你好漂亮呀!",
       		test_information : {
       			group:  "你好漂亮啊", 
       			stack: [[1]],
                	 wordlist:  [{'n': '你好', 'k': 'l', 's': 0, 'p': None}, 
              					{'n': '漂亮', 'k': 'a', 's': 1, 'p': 'pos'}, 
                				{'n': '啊', 'k': 'zg', 's': 0, 'p': None}],
       			pair:  ('漂亮', '你') 
       		error_type : []	
       		
       	}
       	
       	{
       		_id : 1
       		emo_extremum : 1,
       		text : "你好可爱呀!",
       		test_information : {
       			group:  "你好可爱啊", 
       			stack: [[1]],
                	 wordlist:  [{'n': '你好', 'k': 'l', 's': 0, 'p': None}, 
              					{'n': '可爱', 'k': 'a', 's': 1, 'p': 'pos'}, 
                				{'n': '啊', 'k': 'zg', 's': 0, 'p': None}],
       			pair:  ('漂亮', '你') }
       		error_type : []	
       	}
       	...
       	
       }
       ```

       

    4. error_group ( 程序出错原因分组 )

    | Field           | Type    | Description |
    | --------------- | ------- | ----------- |
    | _id             | Integer | 文档表示ID  |
    | group_name_list | String  | 分组名      |
    |                 |         |             |

  * 示例 : 

    1. 

    ``` json
    {
    	_id : 0,
    	group_name_list : ["词典问题", "训练模型问题", "算法问题"]
    }
    
    ```

    
